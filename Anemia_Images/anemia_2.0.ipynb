{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831bba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Columns: ['IMAGE_ID', 'HB_LEVEL', 'Severity', 'Age(Months)', 'GENDER', 'REMARK', 'HOSPITAL', 'CITY/TOWN', 'MUNICIPALITY/DISTRICT', 'REGION', 'COUNTRY']\n",
      "Shape: (710, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Update these paths to match your local machine\n",
    "DATA_ROOT = r\"D:\\test\\CP-AnemiC\"\n",
    "EXCEL_PATH = os.path.join(DATA_ROOT, \"Anemia_Data_Collection_Sheet.xlsx\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e802785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeHbDataset(Dataset):\n",
    "    def __init__(self, excel_path=None, img_root=None, transform=None, mode=\"train\", image_list=None):\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == \"train\":\n",
    "            df = pd.read_excel(excel_path)\n",
    "            valid_rows = []\n",
    "            for _, row in df.iterrows():\n",
    "                img_id = str(row[\"IMAGE_ID\"])\n",
    "                fname = img_id if img_id.lower().endswith((\".png\", \".jpg\")) else img_id + \".png\"\n",
    "                \n",
    "                path_anemic = os.path.join(self.img_root, \"Anemic\", fname)\n",
    "                path_non_anemic = os.path.join(self.img_root, \"Non-anemic\", fname)\n",
    "\n",
    "                img_path = path_anemic if os.path.exists(path_anemic) else path_non_anemic if os.path.exists(path_non_anemic) else None\n",
    "                \n",
    "                if img_path:\n",
    "                    valid_rows.append({\"HB_LEVEL\": row[\"HB_LEVEL\"], \"__FULL_PATH__\": img_path})\n",
    "            self.df = pd.DataFrame(valid_rows)\n",
    "        else:\n",
    "            # For testing/inference mode using a list of file paths\n",
    "            self.image_paths = image_list \n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df) if self.mode == \"train\" else len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"train\":\n",
    "            row = self.df.iloc[idx]\n",
    "            img_path = row[\"__FULL_PATH__\"]\n",
    "            hb_value = float(row[\"HB_LEVEL\"])\n",
    "        else:\n",
    "            img_path = self.image_paths[idx]\n",
    "            hb_value = 0.0 # Placeholder for test mode\n",
    "\n",
    "        img_bgr = cv2.imread(img_path)\n",
    "        if img_bgr is None: raise FileNotFoundError(img_path)\n",
    "        \n",
    "        img_bgr = cv2.resize(img_bgr, (224, 224))\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img_tensor = self.transform(img_rgb) if self.transform else T.ToTensor()(img_rgb)\n",
    "        hb_tensor = torch.tensor([hb_value], dtype=torch.float32)\n",
    "\n",
    "        return img_tensor, hb_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1838e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HbNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.backbone.fc = nn.Identity() \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x_img):\n",
    "        feat = self.backbone(x_img)\n",
    "        return self.fc(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686d45ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "class HbNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.backbone.fc = nn.Identity()  # 512 image feats\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),  # Image only!\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)  # Hb prediction\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img):\n",
    "        feat = self.backbone(x_img)\n",
    "        return self.fc(feat)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87f0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 76.2154\n",
      "Epoch 02 | Loss: 26.6839\n",
      "Epoch 03 | Loss: 5.1889\n",
      "Epoch 04 | Loss: 2.8715\n",
      "Epoch 05 | Loss: 2.6853\n",
      "Epoch 06 | Loss: 2.4769\n",
      "Epoch 07 | Loss: 2.2888\n",
      "Epoch 08 | Loss: 2.3175\n",
      "Epoch 09 | Loss: 2.2544\n",
      "Epoch 10 | Loss: 2.2501\n",
      "Epoch 11 | Loss: 2.0842\n",
      "Epoch 12 | Loss: 2.0541\n",
      "Epoch 13 | Loss: 1.9768\n",
      "Epoch 14 | Loss: 1.9108\n",
      "Epoch 15 | Loss: 1.8622\n",
      "Epoch 16 | Loss: 1.9863\n",
      "Epoch 17 | Loss: 1.9151\n",
      "Epoch 18 | Loss: 1.8270\n",
      "Epoch 19 | Loss: 2.0254\n",
      "Epoch 20 | Loss: 1.9284\n"
     ]
    }
   ],
   "source": [
    "# Setup Data\n",
    "train_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_ds = EyeHbDataset(excel_path=EXCEL_PATH, img_root=DATA_ROOT, transform=train_transform, mode=\"train\")\n",
    "train_indices, val_indices = train_test_split(range(len(full_ds)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(torch.utils.data.Subset(full_ds, train_indices), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(torch.utils.data.Subset(full_ds, val_indices), batch_size=32)\n",
    "\n",
    "model = HbNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop logic from your notebook\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, hbs in loader:\n",
    "        imgs, hbs = imgs.to(device), hbs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, hbs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "# Run for 20 epochs\n",
    "for epoch in range(1, 21):\n",
    "    loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"best_hb_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0d65a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Anemia Accuracy: 75.4%\n"
     ]
    }
   ],
   "source": [
    "def anemia_from_hb(hb): \n",
    "    # Returns 1 if Anemic (below 12.5), 0 otherwise\n",
    "    return int(hb < 12.5)\n",
    "\n",
    "def eval_anemia_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, hbs_true in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            hbs_true = hbs_true.to(device)\n",
    "            \n",
    "            # Get numerical predictions from the model\n",
    "            hbs_pred = model(imgs)\n",
    "            \n",
    "            # Convert both true and predicted Hb to binary (Anemic vs Non-Anemic)\n",
    "            for i in range(len(hbs_true)):\n",
    "                pred_label = anemia_from_hb(hbs_pred[i].item())\n",
    "                true_label = anemia_from_hb(hbs_true[i].item())\n",
    "                \n",
    "                if pred_label == true_label:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "val_accuracy = eval_anemia_accuracy(model, val_loader, device)\n",
    "print(f\"Validation Anemia Accuracy: {val_accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41154c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
